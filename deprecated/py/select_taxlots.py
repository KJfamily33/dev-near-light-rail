# Grant Humphries, 2013
# ArcGIS Version:   10.2
# Python Version:   2.7.3
#--------------------------------

import os
import re
import csv
import arcpy
from arcpy import env

# Allow shapefiles to be overwritten and set the current workspace
env.overwriteOutput = True
env.addOutputsToMap = True
# BE SURE TO UPDATE THIS FILE PATH TO THE NEW FOLDER EACH TIME A NEW ANALYSIS IS RUN!!!
env.workspace = '//gisstore/gis/PUBLIC/GIS_Projects/Development_Around_Lightrail/data/2013_12'

# Creates a 'temp' sub-folder to store temporary project output if it doesn't already exist
if not os.path.exists(os.path.join(env.workspace, 'temp')):
	os.makedirs(os.path.join(env.workspace, 'temp'))

# Add project data
isocrones = os.path.join(env.workspace, 'rail_stop_isocrones.shp')
taxlots = '//gisstore/gis/RLIS/TAXLOTS/taxlots.shp'
multi_family = '//gisstore/gis/RLIS/LAND/multifamily_housing_inventory.shp'

# Taxlots will need to be selected based on their location relative to isocrones, the attributes of the
# isocrones that they fall within, and their own attributes, thus a spatial join will be performed
# so that all of the pertainent information will be contained within a single dataset
def joinIsocronesToProp(prop_data, name, dissolve_fields, unique_id, accrual_unit):
	prop_iso_join = 'in_memory/' + name + '_iso_join'
	join_operation = 'JOIN_ONE_TO_MANY'
	join_type = 'KEEP_COMMON'
	arcpy.SpatialJoin_analysis(prop_data, isocrones, prop_iso_join, join_operation, join_type)

	prop_iso_dissolve = os.path.join(env.workspace, 'temp/' + name + '_iso_dissolve.shp')
	dissolve_fields.append('max_zone')
	stats_fields = [['incpt_year', 'MIN']]
	part_type = 'SINGLE_PART'
	arcpy.Dissolve_management(prop_iso_join, prop_iso_dissolve, dissolve_fields, stats_fields, 
								part_type)

	# Remove any properties that have yearbuilt date before the inception year of the MAX stop
	# isocrone that has been joined to it as (under the terms of this analysis) this construction wasn't
	# influenced by MAX development
	compare_fields = ['YEARBUILT', 'MIN_incpt_']
	with arcpy.da.UpdateCursor(prop_iso_dissolve, compare_fields) as cursor:
		for build_year, incept_year in cursor:
			if build_year < incept_year:
				cursor.deleteRow()

	# Sum the accural units for each MAX zone as well as the for all zones combined, there will be no
	# double counting in the latter, even though some zones share common taxlots
	id_list = []
	global all_max_key
	all_max_key = 'All MAX'
	zone_dict = {all_max_key: 0}
	fields = [unique_id, 'max_zone', accrual_unit]
	with arcpy.da.SearchCursor(prop_iso_dissolve, fields) as cursor:
		for uid, zone, unit in cursor:
			if zone not in zone_dict:
				zone_dict[zone] = unit
			else:
				zone_dict[zone] += unit

			if uid not in id_list:
				zone_dict[all_max_key] += unit
				id_list.append(uid)

	return zone_dict

# Run function for taxlot data, attributes that are to be retained must be included in the dissolve
# field list, running this function on the taxlots file takes about 11 minutes because it is very
# large file, but things should speed up thereafter
tl_name = 'taxlot'
tl_dissolve_fields = ['TLID', 'SITEADDR', 'SITECITY', 'SITEZIP', 'LANDVAL', 'BLDGVAL', 'TOTALVAL', 
						'BLDGSQFT', 'YEARBUILT', 'PROP_CODE', 'LANDUSE', 'SALEDATE', 'SALEPRICE', 'COUNTY']
tl_id = 'TLID'
tl_unit = 'TOTALVAL'
tl_stats = joinIsocronesToProp(taxlots, tl_name, tl_dissolve_fields, tl_id, tl_unit)
max_tl = os.path.join(env.workspace, 'temp/taxlot_iso_dissolve.shp')


# Run the function for multi-familty housing data
mf_name = 'multifam'
mf_dissolve_fields = ['ADDRESS', 'MAIL_CITY', 'UNITS', 'ZIPCODE', 'UNIT_TYPE', 'COUNTY', 'MIXED_USE',
						 'YEARBUILT', 'COMMONNAME', 'DATASOURCE', 'CONFIDENCE', 'METRO_ID']
mf_id = 'METRO_ID'
mf_unit = 'UNITS'
mf_stats = joinIsocronesToProp(multi_family, mf_name, mf_dissolve_fields, mf_id, mf_unit)
max_mf = os.path.join(env.workspace, 'temp/multifam_iso_dissolve.shp')

# Combine format the stats that were generated by the function above in a list such that they 
# can be written neatly to a csv
stats = []
for key in tl_stats:
	stats.append((key, tl_stats[key], mf_stats[key]))

# Sort the stats by group name
stats.sort(key=lambda (group, taxlots, multifam): group)

# Find the index location of the 'total' group and move it to the last position in the list
for index, tup in list(enumerate(stats)):
	if all_max_key in tup:
		am_index = index
		break
stats.insert(len(stats), stats.pop(am_index))

# Add a header tuple to the first position in the list
header = ('Group', 'Total Taxlot Value', 'Multi-Family Units')
stats.insert(0, header)

# Creates a 'csv' sub-folder to store stats ouput if it doesn't already exist
if not os.path.exists(os.path.join(env.workspace, 'csv')):
	os.makedirs(os.path.join(env.workspace, 'csv'))

# Write the stats that have been collected to a csv file
with open(os.path.join(env.workspace, 'csv/development_stats.csv'), 'wb') as dev_stats:
	csv_writer = csv.writer(dev_stats)
	for entry in stats:
		csv_writer.writerow(entry)

#------------------------------------------------------------------------------------------------
# The portion of the script below will assign each taxlot in the Portland Metro area a 'yearbuilt'
# based on which MAX station it is closest to.  This will ultimately be used to create an approximation
# of growth region wide that can be compared to growth around MAX stations

# Add datasets for next phase of project which is determing taxlots position to critical regional boundaries
ugb = '//gisstore/gis/Rlis/BOUNDARY/ugb.shp'
tm_district = '//gisstore/gis/TRIMET/tm_fill.shp'
cities = '//gisstore/gis/Rlis/BOUNDARY/cty_fill.shp'

# note that this dataset is created with create_isocrones.py which must be run first
stops_with_zone = os.path.join(env.workspace, 'temp/max_stops_with_zone.shp')

# I'm only interested in the 9 most populuous cities in the TM district in the case, so I need to isolate them
# and combine them into a single geometry
nine_cities = 'in_memory/nine_cities'
arcpy.CopyFeatures_management(cities, nine_cities)

nine_cities_list = ['Portland', 'Gresham', 'Hillsboro', 'Beaverton', 'Tualatin', 
					'Tigard', 'Lake Oswego', 'Oregon City', 'West Linn']
fields = ['SHAPE@', 'CITYNAME']
with arcpy.da.UpdateCursor(nine_cities, fields) as cursor:
	for geom, c_name in cursor:
		if c_name not in nine_cities_list:
			cursor.deleteRow()

# create a mapping from the fid for each stop to its inception year
stop_year_dict = {}
fields = ['OID@', 'incpt_year']
with arcpy.da.SearchCursor(stops_with_zone, fields) as cursor:
	for oid, inception_year in cursor:
		stop_year_dict[oid] = inception_year

def createRegionalPropComparison(prop_data, prop_type, prop_fields, max_prop):
	# Find the nearest MAX stop to each tax lot
	prop_near_stops_table = 'temp/' + prop_type + '_near_max_stops_tbl'
	arcpy.GenerateNearTable_analysis(prop_data, stops_with_zone, prop_near_stops_table)

	# Create a mapping from the taxlots fid to its nearest stop
	taxlot2stops_dict = {}
	fields = ['IN_FID', 'NEAR_FID']
	with arcpy.da.SearchCursor(prop_near_stops_table, fields) as cursor:
		for tl_fid, stop_fid in cursor:
			taxlot2stops_dict[tl_fid] = stop_fid

	# Update taxlot2stops_dict such that the taxlot's fid maps to the inception year of its nearest MAX stop
	for key, value in taxlot2stops_dict.iteritems():
		taxlot2stops_dict[key] = stop_year_dict[value]

	# Create a new feature class to store a subset of taxlots
	new_development = os.path.join(env.workspace, 'new_dev_' + prop_type + '.shp')
	geom_type = 'POLYGON'
	sr = arcpy.SpatialReference(2913)
	arcpy.CreateFeatureclass_management(os.path.dirname(new_development), os.path.basename(new_development), 
											geom_type, spatial_reference=sr)

	# Note that the 'prop_fields' parameter must be a list of tuples with each tuple containing the field name, 
	# then the field type
	new_fields = [('YEARBUILT', 'SHORT')] + prop_fields + [('MAX_YEAR', 'SHORT')] 
	for f_name, f_type in new_fields:
		arcpy.AddField_management(new_development, f_name, f_type)

	# Drop default field that is automatically added when a new feature class is created
	drop_field = 'Id'
	arcpy.DeleteField_management(new_development, drop_field)

	# For all properties that have development more recently than their nearest MAX stop was built, add them to the
	# newly created feature class
	fields = ['SHAPE@'] + [f_name for f_name, f_type in new_fields]
	i_cursor = arcpy.da.InsertCursor(new_development, fields)

	# The fields list is sliced here because the source prop data doesn't have the 'MAX_YEAR' field which is where
	# the inception date of the properties nearest max stop will be stored
	fields = ['OID@', 'SHAPE@', 'YEARBUILT'] + [f_name for f_name, f_type in prop_fields]
	with arcpy.da.SearchCursor(prop_data, fields) as cursor:
		for row in cursor:
			# row[0] = object ID, row[1] = geom, row[2] = year built
			if row[2] >= taxlot2stops_dict[row[0]]:
				# The OID must before removed and the 'max year' must be added the row before it is inserted into
				# the new development feature class
				new_dev_row = list(row[1:])
				new_dev_row.append(taxlot2stops_dict[row[0]])
				i_cursor.insertRow(new_dev_row)

	del i_cursor

	# Convert properties to points for spatial comparision purposes, if a property is contiguous to one
	# of the comparison areas I'm considering that outside, but with polygons I would get a false positive
	new_dev_pt = 'in_memory/new_dev_' + prop_type + '_points'
	point_loc = 'INSIDE'
	arcpy.FeatureToPoint_management(new_development, new_dev_pt, point_loc)

	global poly2point_dict
	poly2point_dict = {}
	fields = ['OID@', 'ORIG_FID']
	with arcpy.da.SearchCursor(new_dev_pt, fields) as cursor:
		for oid, orig_oid in cursor:
			poly2point_dict[orig_oid] = oid

	ugb_name = prop_type + '_ugb'
	ugb_out_field = 'UGB'
	compareToBoundary(new_development ,new_dev_pt, ugb, ugb_name, ugb_out_field)

	tm_dist_name = prop_type + '_tm_dist'
	tm_dist_out_field = 'TM_DIST'
	compareToBoundary(new_development, new_dev_pt, tm_district, tm_dist_name, tm_dist_out_field)

	nine_cities_name = prop_type + '_9_cities'
	nine_cities_out_field = 'NINE_CITY'
	compareToBoundary(new_development, new_dev_pt, nine_cities, nine_cities_name, nine_cities_out_field)

	max_prop_name = prop_type + '_near_max'
	max_prop_out_field = 'NEAR_MAX'
	compareToBoundary(new_development, new_dev_pt, max_prop, max_prop_name, max_prop_out_field)

	return new_development


# Note that this function can (and should) only be called inside the createRegionalPropComparison function
# due to teh reference to the poly2point_dict
def compareToBoundary(target_feats, target_pts_fc, compare_feats, compare_name, output_field):
	# Keep in mind that if a target feature is further from all near features than the search radius (which is
	# very small in this case, it will not have any entry in the near table)
	compare_table = 'in_memory/' + compare_name + '_compare_table'
	search_radius = '1 FEET'
	arcpy.GenerateNearTable_analysis(target_pts_fc, compare_feats, compare_table, search_radius)

	compare_dict = {}
	fields = ['IN_FID', 'NEAR_DIST']
	with arcpy.da.SearchCursor(compare_table, fields) as cursor:
		for target_fid, near_dist in cursor:
			if near_dist == 0:
				compare_dict[target_fid] = 'yes'

	f_type = 'TEXT'
	arcpy.AddField_management(target_feats, output_field, f_type)

	fields = ['OID@', output_field]
	with arcpy.da.UpdateCursor(target_feats, fields) as cursor:
		for oid, compare_output in cursor:
			try:
				compare_output = compare_dict[poly2point_dict[oid]]
			except:
				compare_output = 'no'
			
			cursor.updateRow((oid, compare_output))


# The 'YEARBUILT' field is already included as a part of the function so don't add it here
tl_name = 'taxlot'
tl_fields = [('TLID', 'TEXT'), ('TOTALVAL', 'LONG')]
tl_comparison = createRegionalPropComparison(taxlots, tl_name, tl_fields, max_tl)

mf_name = 'multifam'
mf_fields = [('METRO_ID', 'LONG'), ('UNITS', 'SHORT')]
mf_comparison = createRegionalPropComparison(multi_family, mf_name, mf_fields, max_mf)